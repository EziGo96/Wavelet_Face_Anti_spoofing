{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8b7616d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%tensorflow_version 2.x\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from skimage.io import imread, imsave\n",
    "from skimage.transform import resize \n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications import vgg16\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cc7459",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "675952df",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfds.disable_progress_bar()\n",
    "\n",
    "splits = ['train[:80%]', 'train[80%:90%]', 'train[90%:]']\n",
    "\n",
    "# load the dataset given the splits defined above\n",
    "splits, info = tfds.load('cats_vs_dogs', with_info=True, as_supervised=True, split = splits)\n",
    "\n",
    "(train_examples, validation_examples, test_examples) = splits\n",
    "\n",
    "num_examples = info.splits['train'].num_examples\n",
    "num_classes = info.features['label'].num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "985d9b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "IMAGE_SIZE = (224, 224)\n",
    "\n",
    "# resizes the image and normalizes the pixel values\n",
    "def format_image(image, label):\n",
    "  image = tf.image.resize(image, IMAGE_SIZE) / 255.0\n",
    "  return  image, label\n",
    "\n",
    "# prepare batches\n",
    "train_batches = train_examples.shuffle(num_examples // 4).map(format_image).batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "validation_batches = validation_examples.map(format_image).batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "test_batches = test_examples.map(format_image).batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a221d61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "  # load the base VGG16 model\n",
    "  base_model = vgg16.VGG16(input_shape=IMAGE_SIZE + (3,), \n",
    "                      weights='imagenet', \n",
    "                      include_top=False)\n",
    "  \n",
    "  # add a GAP layer\n",
    "  output = layers.GlobalAveragePooling2D()(base_model.output)\n",
    "\n",
    "  # output has two neurons for the 2 classes (cats and dogs)\n",
    "  output = layers.Dense(2, activation='softmax')(output)\n",
    "\n",
    "  # set the inputs and outputs of the model\n",
    "  model = Model(base_model.input, output)\n",
    "\n",
    "  # freeze the earlier layers\n",
    "  for layer in base_model.layers[:-4]:\n",
    "      layer.trainable=False\n",
    "\n",
    "  # choose the optimizer\n",
    "  optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "\n",
    "  # configure the model for training\n",
    "  model.compile(loss='sparse_categorical_crossentropy', \n",
    "                optimizer=optimizer, \n",
    "                metrics=['accuracy'])\n",
    "  \n",
    "  # display the summary\n",
    "  model.summary()\n",
    "  \n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7d994cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 1s 0us/step\n",
      "58900480/58889256 [==============================] - 1s 0us/step\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 14,715,714\n",
      "Trainable params: 7,080,450\n",
      "Non-trainable params: 7,635,264\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f49490fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "200/582 [=========>....................] - ETA: 48:50 - loss: 2.4931 - accuracy: 0.4972"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20380/1699320739.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m model.fit(train_batches,\n\u001b[0m\u001b[0;32m      3\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m           validation_data=validation_batches)\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1182\u001b[0m                 _r=1):\n\u001b[0;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3037\u001b[0m       (graph_function,\n\u001b[0;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3039\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1962\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1963\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS = 3\n",
    "model.fit(train_batches,\n",
    "          epochs=EPOCHS,\n",
    "          validation_data=validation_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73b0869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select all the layers for which you want to visualize the outputs and store it in a list\n",
    "outputs = [layer.output for layer in model.layers[1:18]]\n",
    "\n",
    "# Define a new model that generates the above output\n",
    "vis_model = Model(model.input, outputs)\n",
    "\n",
    "# store the layer names we are interested in\n",
    "layer_names = []\n",
    "for layer in outputs:\n",
    "    layer_names.append(layer.name.split(\"/\")[0])\n",
    "\n",
    "    \n",
    "print(\"Layers that will be used for visualization: \")\n",
    "print(layer_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6ee980",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_CAM(processed_image, actual_label, layer_name='block5_conv3'):\n",
    "    model_grad = Model([model.inputs], \n",
    "                       [model.get_layer(layer_name).output, model.output])\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_output_values, predictions = model_grad(processed_image)\n",
    "\n",
    "        # watch the conv_output_values\n",
    "        tape.watch(conv_output_values)\n",
    "\n",
    "        ## Use binary cross entropy loss\n",
    "        ## actual_label is 0 if cat, 1 if dog\n",
    "        # get prediction probability of dog\n",
    "        # If model does well, \n",
    "        # pred_prob should be close to 0 if cat, close to 1 if dog\n",
    "        pred_prob = predictions[:,1] \n",
    "        \n",
    "        # make sure actual_label is a float, like the rest of the loss calculation\n",
    "        actual_label = tf.cast(actual_label, dtype=tf.float32)\n",
    "        \n",
    "        # add a tiny value to avoid log of 0\n",
    "        smoothing = 0.00001 \n",
    "        \n",
    "        # Calculate loss as binary cross entropy\n",
    "        loss = -1 * (actual_label * tf.math.log(pred_prob + smoothing) + (1 - actual_label) * tf.math.log(1 - pred_prob + smoothing))\n",
    "        print(f\"binary loss: {loss}\")\n",
    "    \n",
    "    # get the gradient of the loss with respect to the outputs of the last conv layer\n",
    "    grads_values = tape.gradient(loss, conv_output_values)\n",
    "    grads_values = K.mean(grads_values, axis=(0,1,2))\n",
    "    \n",
    "    conv_output_values = np.squeeze(conv_output_values.numpy())\n",
    "    grads_values = grads_values.numpy()\n",
    "    \n",
    "    # weight the convolution outputs with the computed gradients\n",
    "    for i in range(512): \n",
    "        conv_output_values[:,:,i] *= grads_values[i]\n",
    "    heatmap = np.mean(conv_output_values, axis=-1)\n",
    "    \n",
    "    heatmap = np.maximum(heatmap, 0)\n",
    "    heatmap /= heatmap.max()\n",
    "    \n",
    "    del model_grad, conv_output_values, grads_values, loss\n",
    "   \n",
    "    return heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad68c3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_sample(idx=None):\n",
    "    \n",
    "    # if image index is specified, get that image\n",
    "    if idx:\n",
    "        for img, label in test_batches.take(idx):\n",
    "            sample_image = img[0]\n",
    "            sample_label = label[0]\n",
    "    # otherwise if idx is not specified, get a random image\n",
    "    else:\n",
    "        for img, label in test_batches.shuffle(1000).take(1):\n",
    "            sample_image = img[0]\n",
    "            sample_label = label[0]\n",
    "    \n",
    "    sample_image_processed = np.expand_dims(sample_image, axis=0)\n",
    "    \n",
    "    activations = vis_model.predict(sample_image_processed)\n",
    "    \n",
    "    pred_label = np.argmax(model.predict(sample_image_processed), axis=-1)[0]\n",
    "    \n",
    "    sample_activation = activations[0][0,:,:,16]\n",
    "    \n",
    "    sample_activation-=sample_activation.mean()\n",
    "    sample_activation/=sample_activation.std()\n",
    "    \n",
    "    sample_activation *=255\n",
    "    sample_activation = np.clip(sample_activation, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    heatmap = get_CAM(sample_image_processed, sample_label)\n",
    "    heatmap = cv2.resize(heatmap, (sample_image.shape[0], sample_image.shape[1]))\n",
    "    heatmap = heatmap *255\n",
    "    heatmap = np.clip(heatmap, 0, 255).astype(np.uint8)\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_HOT)\n",
    "    converted_img = sample_image.numpy()\n",
    "    super_imposed_image = cv2.addWeighted(converted_img, 0.8, heatmap.astype('float32'), 2e-3, 0.0)\n",
    "\n",
    "    f,ax = plt.subplots(2,2, figsize=(15,8))\n",
    "\n",
    "    ax[0,0].imshow(sample_image)\n",
    "    ax[0,0].set_title(f\"True label: {sample_label} \\n Predicted label: {pred_label}\")\n",
    "    ax[0,0].axis('off')\n",
    "    \n",
    "    ax[0,1].imshow(sample_activation)\n",
    "    ax[0,1].set_title(\"Random feature map\")\n",
    "    ax[0,1].axis('off')\n",
    "    \n",
    "    ax[1,0].imshow(heatmap)\n",
    "    ax[1,0].set_title(\"Class Activation Map\")\n",
    "    ax[1,0].axis('off')\n",
    "    \n",
    "    ax[1,1].imshow(super_imposed_image)\n",
    "    ax[1,1].set_title(\"Activation map superimposed\")\n",
    "    ax[1,1].axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "  \n",
    "    return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e088fe32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose an image index to show, or leave it as None to get a random image\n",
    "activations = show_sample(idx=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c0d656",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_intermediate_activations(layer_names, activations):\n",
    "    assert len(layer_names)==len(activations), \"Make sure layers and activation values match\"\n",
    "    images_per_row=16\n",
    "    \n",
    "    for layer_name, layer_activation in zip(layer_names, activations):\n",
    "        nb_features = layer_activation.shape[-1]\n",
    "        size= layer_activation.shape[1]\n",
    "\n",
    "        nb_cols = nb_features // images_per_row\n",
    "        grid = np.zeros((size*nb_cols, size*images_per_row))\n",
    "\n",
    "        for col in range(nb_cols):\n",
    "            for row in range(images_per_row):\n",
    "                feature_map = layer_activation[0,:,:,col*images_per_row + row]\n",
    "                feature_map -= feature_map.mean()\n",
    "                feature_map /= feature_map.std()\n",
    "                feature_map *=255\n",
    "                feature_map = np.clip(feature_map, 0, 255).astype(np.uint8)\n",
    "\n",
    "                grid[col*size:(col+1)*size, row*size:(row+1)*size] = feature_map\n",
    "\n",
    "        scale = 1./size\n",
    "        plt.figure(figsize=(scale*grid.shape[1], scale*grid.shape[0]))\n",
    "        plt.title(layer_name)\n",
    "        plt.grid(False)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(grid, aspect='auto', cmap='viridis')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a190b3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_intermediate_activations(activations=activations, \n",
    "                                   layer_names=layer_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675c6c63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
